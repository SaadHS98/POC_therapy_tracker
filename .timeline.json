{
  "timeline_index": 63,
  "planner": {
    "Team Leader": {
      "1": {
        "task_id": "1",
        "dependent_task_ids": [],
        "instruction": "Analyze the therapy session data files, note template explanation, and create a data analysis plan for tracking therapy progress between sessions.",
        "task_type": "general",
        "code": "",
        "result": "",
        "is_success": false,
        "is_finished": true,
        "assignee": "David",
        "start_at": 1748859033.8268487,
        "end_at": 1748859577.3355052
      },
      "current_task_id": "4",
      "2": {
        "task_id": "2",
        "dependent_task_ids": [
          "1"
        ],
        "instruction": "Create a product requirement document (PRD) for the therapy progress tracking POC, including UI requirements, AI approach specifications, and documentation needs.",
        "task_type": "general",
        "code": "",
        "result": "",
        "is_success": false,
        "is_finished": true,
        "assignee": "Emma",
        "start_at": 1748859577.3355415,
        "end_at": 1748859771.3919666
      },
      "3": {
        "task_id": "3",
        "dependent_task_ids": [
          "2"
        ],
        "instruction": "Design a system architecture for the therapy progress tracking application that includes the UI component, AI backend, and data processing pipeline.",
        "task_type": "general",
        "code": "",
        "result": "",
        "is_success": false,
        "is_finished": false,
        "assignee": "Bob",
        "start_at": 1748859771.3920023,
        "end_at": 1749042300.2550359
      },
      "4": {
        "task_id": "4",
        "dependent_task_ids": [],
        "instruction": "Develop a complete, deployable web application for tracking therapy progress that integrates both UI and AI components based on the system architecture. The application should use Streamlit for the frontend, FastAPI for the backend API, and incorporate the necessary AI models for symptom extraction and progress tracking.",
        "task_type": "general",
        "code": "",
        "result": "",
        "is_success": false,
        "is_finished": false,
        "assignee": "Alex",
        "start_at": 1749042300.255043
      }
    },
    "Data Analyst": {
      "1": {
        "task_id": "1",
        "dependent_task_ids": [],
        "instruction": "Read client therapy session data files to understand their structure and content",
        "task_type": "eda",
        "code": "\nimport json\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\n\n# Function to read and parse JSON data from therapy session notes\ndef read_therapy_notes(file_path):\n    with open(file_path, 'r') as file:\n        # Remove line numbers and parse JSON\n        content = file.read()\n        # Strip line numbers (assuming format like \"001|{\")\n        lines = content.split('\\n')\n        clean_lines = []\n        for line in lines:\n            if '|' in line:\n                clean_lines.append(line.split('|', 1)[1])\n            else:\n                clean_lines.append(line)\n        clean_content = '\\n'.join(clean_lines)\n        \n        # Parse JSON\n        try:\n            return json.loads(clean_content)\n        except json.JSONDecodeError as e:\n            print(f\"Error parsing JSON from {file_path}: {e}\")\n            return None\n\n# Define file paths\nbase_path = \"/data/chats/uidp1d/workspace/uploads/\"\nfiles = {\n    \"client1_session1\": f\"{base_path}client1_session1.txt\",\n    \"client1_session2\": f\"{base_path}client1_session2.txt\",\n    \"client2_session1\": f\"{base_path}client2_session1.txt\",\n    \"client2_session2\": f\"{base_path}client2_session2.txt\",\n    \"note_template\": f\"{base_path}note_template_explanation.txt\",\n}\n\n# Read all therapy notes\ntherapy_notes = {}\nfor key, path in files.items():\n    therapy_notes[key] = read_therapy_notes(path)\n    \n# Extract key fields for tracking therapy progress\ndef extract_progress_fields(notes):\n    \"\"\"Extract key fields relevant to therapy progress tracking\"\"\"\n    progress_data = {}\n    \n    # Extract basic session info\n    progress_data[\"brief_summary\"] = notes.get(\"Brief Summary of Session\", \"\")\n    \n    # Extract main complaint\n    progress_data[\"chief_complaint\"] = notes.get(\"Presentation\", {}).get(\"Chief Complaint\", \"\")\n    \n    # Extract symptoms\n    symptoms = notes.get(\"Psychological Factors\", {}).get(\"Symptoms\", {})\n    progress_data[\"symptoms\"] = symptoms\n    \n    # Extract mental status\n    progress_data[\"mental_status\"] = notes.get(\"Mental Status Exam\", {})\n    \n    # Extract progress info\n    progress_data[\"progress\"] = notes.get(\"Progress and Response\", {})\n    \n    # Extract risk assessment\n    progress_data[\"risk\"] = notes.get(\"Risk Assessment\", {})\n    \n    return progress_data\n\n# Extract progress fields from all notes\nprogress_fields = {}\nfor key, notes in therapy_notes.items():\n    if key != \"note_template\" and notes:  # Skip template explanation\n        progress_fields[key] = extract_progress_fields(notes)\n\n# Analyze symptoms and their severity/intensity changes between sessions\ndef analyze_symptom_changes(client_sessions):\n    \"\"\"Analyze changes in symptoms between sessions for a client\"\"\"\n    \n    # Extract sessions for this client\n    sessions = [s for s in client_sessions if s in progress_fields]\n    if len(sessions) < 2:\n        return f\"Not enough sessions to compare for {sessions[0].split('_')[0]}\"\n    \n    changes = []\n    \n    # Compare symptoms from first to last session\n    first_session = progress_fields[sessions[0]]\n    last_session = progress_fields[sessions[1]]\n    \n    # Extract symptom data\n    first_symptoms = first_session[\"symptoms\"]\n    last_symptoms = last_session[\"symptoms\"]\n    \n    # Compare symptom intensity/severity\n    for symptom_key in first_symptoms:\n        if symptom_key in last_symptoms:\n            first_intensity = first_symptoms[symptom_key].get(\"Intensity\", \"\")\n            last_intensity = last_symptoms[symptom_key].get(\"Intensity\", \"\")\n            \n            first_frequency = first_symptoms[symptom_key].get(\"Frequency\", \"\")\n            last_frequency = last_symptoms[symptom_key].get(\"Frequency\", \"\")\n            \n            first_ascendance = first_symptoms[symptom_key].get(\"Ascendance\", \"\")\n            last_ascendance = last_symptoms[symptom_key].get(\"Ascendance\", \"\")\n            \n            changes.append({\n                \"symptom\": first_symptoms[symptom_key].get(\"Description\", symptom_key),\n                \"first_intensity\": first_intensity,\n                \"last_intensity\": last_intensity,\n                \"first_frequency\": first_frequency,\n                \"last_frequency\": last_frequency,\n                \"first_ascendance\": first_ascendance,\n                \"last_ascendance\": last_ascendance,\n            })\n    \n    return changes\n\n# Define client sessions\nclient1_sessions = [\"client1_session1\", \"client1_session2\"]\nclient2_sessions = [\"client2_session1\", \"client2_session2\"]\n\n# Analyze symptom changes for each client\nclient1_changes = analyze_symptom_changes(client1_sessions)\nclient2_changes = analyze_symptom_changes(client2_sessions)\n\nprint(\"=== Client 1 Symptom Changes ===\")\nprint(pd.DataFrame(client1_changes))\n\nprint(\"\\n=== Client 2 Symptom Changes ===\")\nprint(pd.DataFrame(client2_changes))\n\n# Define intensity scale for standardized assessment\nintensity_scale = {\n    \"None\": 0,\n    \"Minimal\": 1,\n    \"Mild\": 2,\n    \"Moderate\": 3,\n    \"High\": 4,\n    \"Severe\": 5\n}\n\n# Define keywords indicating positive vs negative symptom changes\npositive_indicators = [\"improved\", \"reduced\", \"better\", \"lessened\", \"decreased\", \"minimal\"]\nnegative_indicators = [\"worsened\", \"increased\", \"worse\", \"intensified\", \"more\", \"persistent\"]\n\n# Function to score severity/intensity of symptoms\ndef score_intensity(intensity):\n    if not intensity or not isinstance(intensity, str):\n        return None\n    \n    for key, value in intensity_scale.items():\n        if key.lower() in intensity.lower():\n            return value\n    return None\n\n# Function to analyze textual descriptions for sentiment\ndef analyze_symptom_sentiment(description):\n    \"\"\"Simple keyword-based sentiment analysis for symptom descriptions\"\"\"\n    if not description or not isinstance(description, str):\n        return 0\n    \n    sentiment_score = 0\n    description = description.lower()\n    \n    # Check for positive indicators\n    for word in positive_indicators:\n        if word in description:\n            sentiment_score += 1\n            \n    # Check for negative indicators\n    for word in negative_indicators:\n        if word in description:\n            sentiment_score -= 1\n            \n    return sentiment_score\n\n# Function to calculate symptom improvement score\ndef calculate_improvement_score(changes):\n    \"\"\"Calculate an overall improvement score based on symptom changes\"\"\"\n    if not changes or not isinstance(changes, list):\n        return \"No data available\"\n    \n    scores = []\n    \n    for change in changes:\n        # Score based on intensity change\n        intensity_first = score_intensity(change.get(\"first_intensity\"))\n        intensity_last = score_intensity(change.get(\"last_intensity\"))\n        \n        # Score based on text sentiment in ascendance field\n        ascendance_sentiment = analyze_symptom_sentiment(change.get(\"last_ascendance\", \"\"))\n        \n        # Calculate change in intensity (positive means improvement)\n        if intensity_first is not None and intensity_last is not None:\n            intensity_change = intensity_first - intensity_last\n        else:\n            intensity_change = 0\n            \n        # Combine scores (intensity change and sentiment)\n        total_score = intensity_change + ascendance_sentiment\n        scores.append(total_score)\n    \n    if not scores:\n        return \"No scorable symptoms found\"\n    \n    # Average improvement score across all symptoms\n    avg_score = sum(scores) / len(scores)\n    \n    return avg_score\n\n# Calculate improvement scores\nclient1_improvement = calculate_improvement_score(client1_changes)\nclient2_improvement = calculate_improvement_score(client2_changes)\n\nprint(\"\\n=== Overall Improvement Scores ===\")\nprint(f\"Client 1: {client1_improvement}\")\nprint(f\"Client 2: {client2_improvement}\")\n\n# Analyze specific fields that indicate therapeutic progress\ndef analyze_progress_fields(first_session, last_session):\n    \"\"\"Compare specific fields that indicate progress between sessions\"\"\"\n    progress_indicators = {}\n    \n    # Compare response to treatment\n    first_response = first_session[\"progress\"].get(\"Response to Treatment\", \"\")\n    last_response = last_session[\"progress\"].get(\"Response to Treatment\", \"\")\n    progress_indicators[\"treatment_response_change\"] = analyze_symptom_sentiment(last_response) - analyze_symptom_sentiment(first_response)\n    \n    # Compare mental status\n    first_mood = first_session[\"mental_status\"].get(\"Mood and Affect\", \"\")\n    last_mood = last_session[\"mental_status\"].get(\"Mood and Affect\", \"\")\n    progress_indicators[\"mood_change\"] = analyze_symptom_sentiment(last_mood) - analyze_symptom_sentiment(first_mood)\n    \n    # Compare risk assessment\n    first_risk = first_session[\"risk\"].get(\"Hopelessness\", \"\")\n    last_risk = last_session[\"risk\"].get(\"Hopelessness\", \"\")\n    progress_indicators[\"risk_change\"] = analyze_symptom_sentiment(last_risk) - analyze_symptom_sentiment(first_risk)\n    \n    return progress_indicators\n\n# Analyze progress fields for each client\nclient1_progress = analyze_progress_fields(\n    progress_fields[\"client1_session1\"], \n    progress_fields[\"client1_session2\"]\n)\n\nclient2_progress = analyze_progress_fields(\n    progress_fields[\"client2_session1\"], \n    progress_fields[\"client2_session2\"]\n)\n\nprint(\"\\n=== Additional Progress Indicators ===\")\nprint(\"Client 1:\")\nfor key, value in client1_progress.items():\n    print(f\"  {key}: {value}\")\nprint(\"Client 2:\")\nfor key, value in client2_progress.items():\n    print(f\"  {key}: {value}\")\n\n# Summarize key findings\nprint(\"\\n=== Summary of Therapy Progress Analysis ===\")\nprint(\"Key fields identified for tracking therapy progress:\")\nprint(\"1. Symptom intensity/severity changes\")\nprint(\"2. Symptom frequency changes\")\nprint(\"3. Mental status changes (mood and affect)\")\nprint(\"4. Response to treatment assessment\")\nprint(\"5. Risk assessment changes\")\nprint(\"6. Sleep patterns and biological factors\")\n\nprint(\"\\nRecommendations for quantifying progress:\")\nprint(\"1. Use a standardized scale for symptom intensity (None to Severe)\")\nprint(\"2. Track changes in frequency of symptoms using a numerical scale\")\nprint(\"3. Implement sentiment analysis on textual descriptions\")\nprint(\"4. Create a composite progress score combining multiple factors\")\nprint(\"5. Consider using standardized assessments like GAD-7 and PHQ-9\")",
        "result": "\nError parsing JSON from /data/chats/uidp1d/workspace/uploads/note_template_explanation.txt: Expecting value: line 2 column 32 (char 33)\n=== Client 1 Symptom Changes ===\n              symptom first_intensity last_intensity  \\\n0  Anxiety and stress        Moderate           Mild   \n\n                                     first_frequency  \\\n0  Intermittent, with episodes lasting a couple o...   \n\n                            last_frequency  \\\n0  Occasional, with noticeable improvement   \n\n                                    first_ascendance  \\\n0  The symptoms have leveled off after the initia...   \n\n                                     last_ascendance  \n0  Symptoms have decreased following the applicat...  \n\n=== Client 2 Symptom Changes ===\n                                             symptom first_intensity  \\\n0  Stress and anxiety related to recent life chan...        Moderate   \n\n  last_intensity first_frequency  \\\n0           High           Daily   \n\n                                     last_frequency  \\\n0  Multiple times a day, with increasing intensity.   \n\n                  first_ascendance  \\\n0  Persistent at current baseline.   \n\n                                     last_ascendance  \n0  Symptoms are worsening, with the client feelin...  \n\n=== Overall Improvement Scores ===\nClient 1: 2.0\nClient 2: -2.0\n\n=== Additional Progress Indicators ===\nClient 1:\n  treatment_response_change: 0\n  mood_change: 0\n  risk_change: 0\nClient 2:\n  treatment_response_change: 0\n  mood_change: 0\n  risk_change: 0\n\n=== Summary of Therapy Progress Analysis ===\nKey fields identified for tracking therapy progress:\n1. Symptom intensity/severity changes\n2. Symptom frequency changes\n3. Mental status changes (mood and affect)\n4. Response to treatment assessment\n5. Risk assessment changes\n6. Sleep patterns and biological factors\n\nRecommendations for quantifying progress:\n1. Use a standardized scale for symptom intensity (None to Severe)\n2. Track changes in frequency of symptoms using a numerical scale\n3. Implement sentiment analysis on textual descriptions\n4. Create a composite progress score combining multiple factors\n5. Consider using standardized assessments like GAD-7 and PHQ-9",
        "is_success": true,
        "is_finished": true,
        "assignee": "David",
        "start_at": 1748859047.9486454,
        "end_at": 1748859143.3244607
      },
      "current_task_id": "3",
      "2": {
        "task_id": "2",
        "dependent_task_ids": [
          "1"
        ],
        "instruction": "Develop a data analysis approach to extract and compare symptoms between sessions",
        "task_type": "feature engineering",
        "code": "\n# Feature Engineering: Enhanced Symptom Analysis and Standardized Assessment Integration\n\n# Define GAD-7 (Generalized Anxiety Disorder) assessment questions and scoring\ngad7_questions = [\n    \"Feeling nervous, anxious, or on edge\",\n    \"Not being able to stop or control worrying\",\n    \"Worrying too much about different things\",\n    \"Trouble relaxing\",\n    \"Being so restless that it's hard to sit still\",\n    \"Becoming easily annoyed or irritable\",\n    \"Feeling afraid, as if something awful might happen\"\n]\n\n# Define PHQ-9 (Patient Health Questionnaire for Depression) assessment questions and scoring\nphq9_questions = [\n    \"Little interest or pleasure in doing things\",\n    \"Feeling down, depressed, or hopeless\",\n    \"Trouble falling or staying asleep, or sleeping too much\",\n    \"Feeling tired or having little energy\",\n    \"Poor appetite or overeating\",\n    \"Feeling bad about yourself or that you are a failure\",\n    \"Trouble concentrating on things\",\n    \"Moving or speaking so slowly that other people could have noticed\",\n    \"Thoughts that you would be better off dead or of hurting yourself\"\n]\n\n# Define scoring scale for both assessments\nassessment_scale = {\n    \"Not at all\": 0,\n    \"Several days\": 1,\n    \"More than half the days\": 2,\n    \"Nearly every day\": 3\n}\n\n# Enhanced feature extraction for symptoms\ndef extract_enhanced_symptom_features(notes_data):\n    \"\"\"\n    Extract enhanced symptom features from therapy notes including standardized assessment mapping\n    \"\"\"\n    features = {}\n    \n    # Basic features from existing data\n    symptoms = notes_data.get(\"Psychological Factors\", {}).get(\"Symptoms\", {})\n    features[\"symptom_count\"] = len(symptoms)\n    \n    # Extract detailed symptom features\n    intensity_scores = []\n    frequency_words = []\n    symptom_descriptions = []\n    \n    for symptom_key, symptom_data in symptoms.items():\n        # Get raw symptom data\n        description = symptom_data.get(\"Description\", \"\")\n        intensity = symptom_data.get(\"Intensity\", \"\")\n        frequency = symptom_data.get(\"Frequency\", \"\")\n        duration = symptom_data.get(\"Duration\", \"\")\n        ascendance = symptom_data.get(\"Ascendance\", \"\")\n        quote = symptom_data.get(\"Quote (Symptom)\", \"\")\n        \n        # Store symptom data\n        symptom_descriptions.append(description)\n        \n        # Extract intensity score\n        intensity_score = score_intensity(intensity)\n        if intensity_score is not None:\n            intensity_scores.append(intensity_score)\n        \n        # Extract frequency words\n        if frequency:\n            frequency_words.extend([word.lower() for word in frequency.split()])\n    \n    # Calculate average intensity if any scores were found\n    features[\"avg_symptom_intensity\"] = sum(intensity_scores) / len(intensity_scores) if intensity_scores else None\n    features[\"max_symptom_intensity\"] = max(intensity_scores) if intensity_scores else None\n    \n    # Extract frequency indicators\n    frequency_indicators = {\n        \"daily\": 0,\n        \"weekly\": 0, \n        \"monthly\": 0,\n        \"intermittent\": 0,\n        \"constant\": 0,\n        \"occasional\": 0,\n        \"frequent\": 0\n    }\n    \n    for indicator in frequency_indicators:\n        for word in frequency_words:\n            if indicator in word:\n                frequency_indicators[indicator] += 1\n    \n    for indicator, count in frequency_indicators.items():\n        features[f\"frequency_{indicator}\"] = count\n    \n    # Map to standardized assessments (GAD-7 and PHQ-9)\n    features.update(map_to_standardized_assessments(notes_data))\n    \n    # Extract biological factors\n    biological_factors = notes_data.get(\"Biological Factors\", {})\n    \n    # Sleep feature\n    sleep_text = biological_factors.get(\"Sleep\", \"\")\n    features[\"has_sleep_issues\"] = int(bool(sleep_text) and any(word in sleep_text.lower() for word in [\"disturb\", \"issue\", \"problem\", \"insomnia\", \"difficult\", \"irregular\"]))\n    \n    # Additional biological factors as features\n    features[\"has_nutrition_issues\"] = int(bool(biological_factors.get(\"Nutrition\", \"\")))\n    features[\"has_substance_use\"] = int(bool(biological_factors.get(\"Substances\", \"\")))\n    \n    # Extract mental status exam features\n    mental_status = notes_data.get(\"Mental Status Exam\", {})\n    \n    # Mood and affect features\n    mood_text = mental_status.get(\"Mood and Affect\", \"\")\n    features[\"mood_negative\"] = int(bool(mood_text) and any(word in mood_text.lower() for word in [\"anxious\", \"depressed\", \"sad\", \"overwhelm\", \"stress\", \"negative\"]))\n    features[\"mood_positive\"] = int(bool(mood_text) and any(word in mood_text.lower() for word in [\"positive\", \"good\", \"improve\", \"better\", \"happy\", \"calm\"]))\n    \n    # Risk assessment features\n    risk = notes_data.get(\"Risk Assessment\", {})\n    features[\"has_hopelessness\"] = int(bool(risk.get(\"Hopelessness\", \"\")) and \"No\" not in risk.get(\"Hopelessness\", \"\"))\n    features[\"has_suicidal_thoughts\"] = int(bool(risk.get(\"Suicidal Thoughts or Attempts\", \"\")) and \"No\" not in risk.get(\"Suicidal Thoughts or Attempts\", \"\"))\n    \n    return features\n\ndef map_to_standardized_assessments(notes_data):\n    \"\"\"\n    Map symptoms and indicators to standardized assessments (GAD-7 and PHQ-9)\n    Uses the notes content to approximate scores on these assessments\n    \"\"\"\n    features = {}\n    \n    # Extract all relevant text for analysis\n    symptoms_text = \"\"\n    mental_status_text = \"\"\n    progress_text = \"\"\n    \n    # Get symptoms descriptions\n    symptoms = notes_data.get(\"Psychological Factors\", {}).get(\"Symptoms\", {})\n    for symptom_key, symptom_data in symptoms.items():\n        symptoms_text += symptom_data.get(\"Description\", \"\") + \" \"\n        symptoms_text += symptom_data.get(\"Quote (Symptom)\", \"\") + \" \"\n    \n    # Get mental status descriptions\n    mental_status = notes_data.get(\"Mental Status Exam\", {})\n    for key, value in mental_status.items():\n        mental_status_text += value + \" \"\n    \n    # Get progress descriptions\n    progress = notes_data.get(\"Progress and Response\", {})\n    for key, value in progress.items():\n        progress_text += value + \" \"\n    \n    # Combine texts\n    all_text = (symptoms_text + \" \" + mental_status_text + \" \" + progress_text).lower()\n    \n    # Score GAD-7 questions based on text evidence\n    gad7_scores = []\n    for question in gad7_questions:\n        keywords = [word.lower() for word in question.split() if len(word) > 3]\n        evidence_count = sum(1 for keyword in keywords if keyword in all_text)\n        \n        # Convert evidence to GAD-7 scale (0-3)\n        if evidence_count == 0:\n            score = 0  # Not at all\n        elif evidence_count == 1:\n            score = 1  # Several days\n        elif evidence_count == 2:\n            score = 2  # More than half the days\n        else:\n            score = 3  # Nearly every day\n        \n        gad7_scores.append(score)\n        features[f\"gad7_{keywords[0]}\"] = score  # Use first keyword as feature name\n    \n    # Calculate GAD-7 total score\n    features[\"gad7_total_score\"] = sum(gad7_scores)\n    \n    # Interpret GAD-7 score\n    if features[\"gad7_total_score\"] < 5:\n        features[\"gad7_severity\"] = \"Minimal anxiety\"\n    elif features[\"gad7_total_score\"] < 10:\n        features[\"gad7_severity\"] = \"Mild anxiety\"\n    elif features[\"gad7_total_score\"] < 15:\n        features[\"gad7_severity\"] = \"Moderate anxiety\"\n    else:\n        features[\"gad7_severity\"] = \"Severe anxiety\"\n    \n    # Score PHQ-9 questions based on text evidence\n    phq9_scores = []\n    for question in phq9_questions:\n        keywords = [word.lower() for word in question.split() if len(word) > 3]\n        evidence_count = sum(1 for keyword in keywords if keyword in all_text)\n        \n        # Convert evidence to PHQ-9 scale (0-3)\n        if evidence_count == 0:\n            score = 0  # Not at all\n        elif evidence_count == 1:\n            score = 1  # Several days\n        elif evidence_count == 2:\n            score = 2  # More than half the days\n        else:\n            score = 3  # Nearly every day\n        \n        phq9_scores.append(score)\n        features[f\"phq9_{keywords[0]}\"] = score  # Use first keyword as feature name\n    \n    # Calculate PHQ-9 total score\n    features[\"phq9_total_score\"] = sum(phq9_scores)\n    \n    # Interpret PHQ-9 score\n    if features[\"phq9_total_score\"] < 5:\n        features[\"phq9_severity\"] = \"Minimal depression\"\n    elif features[\"phq9_total_score\"] < 10:\n        features[\"phq9_severity\"] = \"Mild depression\"\n    elif features[\"phq9_total_score\"] < 15:\n        features[\"phq9_severity\"] = \"Moderate depression\"\n    elif features[\"phq9_total_score\"] < 20:\n        features[\"phq9_severity\"] = \"Moderately severe depression\"\n    else:\n        features[\"phq9_severity\"] = \"Severe depression\"\n    \n    return features\n\ndef extract_nlp_features(text):\n    \"\"\"\n    Extract NLP features from text such as sentiment, emotion words, and cognitive indicators\n    \"\"\"\n    features = {}\n    \n    # Simple sentiment analysis\n    sentiment_score = analyze_symptom_sentiment(text)\n    features[\"sentiment_score\"] = sentiment_score\n    \n    # Count emotion words\n    emotion_categories = {\n        \"anxiety\": [\"anxious\", \"worried\", \"nervous\", \"tense\", \"frightened\", \"panicked\", \"afraid\"],\n        \"depression\": [\"sad\", \"depressed\", \"hopeless\", \"worthless\", \"empty\", \"miserable\", \"lonely\"],\n        \"anger\": [\"angry\", \"irritable\", \"frustrated\", \"annoyed\", \"hostile\", \"resentful\", \"enraged\"],\n        \"positive\": [\"happy\", \"calm\", \"peaceful\", \"relaxed\", \"content\", \"joy\", \"pleasant\", \"optimistic\"]\n    }\n    \n    text_lower = text.lower()\n    for category, words in emotion_categories.items():\n        count = sum(1 for word in words if word in text_lower)\n        features[f\"{category}_words\"] = count\n    \n    # Count cognitive distortion indicators\n    cognitive_distortions = [\n        \"always\", \"never\", \"should\", \"must\", \"can't\", \"impossible\", \n        \"terrible\", \"horrible\", \"awful\", \"worst\", \"everyone\", \"no one\"\n    ]\n    features[\"cognitive_distortion_count\"] = sum(1 for word in cognitive_distortions if word in text_lower)\n    \n    return features\n\ndef calculate_symptom_change_vectors(first_session, last_session):\n    \"\"\"\n    Calculate symptom change vectors between two sessions using enhanced feature extraction\n    \"\"\"\n    # Extract enhanced features from both sessions\n    first_features = extract_enhanced_symptom_features(first_session)\n    last_features = extract_enhanced_symptom_features(last_session)\n    \n    # Calculate changes in features\n    changes = {}\n    for key in set(first_features.keys()).union(set(last_features.keys())):\n        first_value = first_features.get(key)\n        last_value = last_features.get(key)\n        \n        # Skip non-numeric or missing values\n        if first_value is None or last_value is None:\n            continue\n        try:\n            if isinstance(first_value, (int, float)) and isinstance(last_value, (int, float)):\n                changes[f\"{key}_change\"] = last_value - first_value\n        except Exception:\n            continue\n    \n    # Add raw feature values from both sessions\n    for key, value in first_features.items():\n        changes[f\"first_{key}\"] = value\n    for key, value in last_features.items():\n        changes[f\"last_{key}\"] = value\n    \n    return changes\n\ndef calculate_comprehensive_progress_score(changes):\n    \"\"\"\n    Calculate a comprehensive progress score based on multiple factors\n    \"\"\"\n    if not changes:\n        return {\"progress_score\": None, \"score_factors\": {}}\n    \n    score_factors = {}\n    \n    # Weight factors (adjust as needed)\n    weights = {\n        \"gad7_total_score_change\": -2.0,  # Negative because reduction is good\n        \"phq9_total_score_change\": -2.0,  # Negative because reduction is good\n        \"avg_symptom_intensity_change\": -1.5,  # Negative because reduction is good\n        \"mood_positive_change\": 1.0,  # Positive because increase is good\n        \"mood_negative_change\": -1.0,  # Negative because reduction is good\n        \"has_sleep_issues_change\": -1.0,  # Negative because reduction is good\n        \"has_hopelessness_change\": -2.0,  # Negative because reduction is good\n        \"has_suicidal_thoughts_change\": -3.0,  # Negative because reduction is good\n        \"sentiment_score_change\": 1.0,  # Positive because increase is good\n    }\n    \n    weighted_scores = []\n    for factor, weight in weights.items():\n        if factor in changes:\n            score_factors[factor] = changes[factor] * weight\n            weighted_scores.append(score_factors[factor])\n    \n    if not weighted_scores:\n        return {\"progress_score\": None, \"score_factors\": {}}\n    \n    # Calculate total weighted score\n    total_weighted_score = sum(weighted_scores)\n    \n    # Normalize to a -10 to +10 scale\n    max_possible_score = sum(abs(w) for w in weights.values())\n    normalized_score = (total_weighted_score / max_possible_score) * 10\n    \n    # Round to 2 decimal places\n    normalized_score = round(normalized_score, 2)\n    \n    return {\n        \"progress_score\": normalized_score,\n        \"score_factors\": score_factors\n    }\n\ndef interpret_progress_score(score):\n    \"\"\"\n    Interpret the progress score with qualitative descriptions\n    \"\"\"\n    if score is None:\n        return \"Insufficient data to assess progress\"\n    \n    if score > 7:\n        return \"Excellent progress - significant symptom reduction and improved functioning\"\n    elif score > 4:\n        return \"Good progress - notable symptom reduction and some improved functioning\"\n    elif score > 1:\n        return \"Moderate progress - some symptom reduction with minimal functional improvement\"\n    elif score > -1:\n        return \"Minimal change - symptom levels are relatively stable\"\n    elif score > -4:\n        return \"Slight deterioration - some symptom increase with minimal functional decline\"\n    elif score > -7:\n        return \"Moderate deterioration - notable symptom increase and some functional decline\"\n    else:\n        return \"Significant deterioration - substantial symptom increase and functional decline\"\n\ndef generate_progress_report(client_id, sessions, change_vectors, progress_score):\n    \"\"\"\n    Generate a comprehensive progress report for a client\n    \"\"\"\n    report = {\n        \"client_id\": client_id,\n        \"session_count\": len(sessions),\n        \"first_session\": sessions[0],\n        \"last_session\": sessions[-1],\n        \"symptom_changes\": change_vectors,\n        \"progress_score\": progress_score[\"progress_score\"],\n        \"progress_interpretation\": interpret_progress_score(progress_score[\"progress_score\"]),\n        \"score_factors\": progress_score[\"score_factors\"],\n        \"standardized_assessments\": {\n            \"first_session\": {\n                \"gad7\": change_vectors.get(\"first_gad7_total_score\"),\n                \"phq9\": change_vectors.get(\"first_phq9_total_score\"),\n                \"gad7_severity\": change_vectors.get(\"first_gad7_severity\"),\n                \"phq9_severity\": change_vectors.get(\"first_phq9_severity\"),\n            },\n            \"last_session\": {\n                \"gad7\": change_vectors.get(\"last_gad7_total_score\"),\n                \"phq9\": change_vectors.get(\"last_phq9_total_score\"),\n                \"gad7_severity\": change_vectors.get(\"last_gad7_severity\"),\n                \"phq9_severity\": change_vectors.get(\"last_phq9_severity\"),\n            }\n        }\n    }\n    \n    return report\n\n# Extract detailed features from therapy sessions\n# Use NLP features on symptom descriptions and other text fields\ndef enhance_client_change_analysis():\n    \"\"\"\n    Enhance client change analysis with NLP features and standardized assessments\n    \"\"\"\n    client_reports = {}\n    \n    # Process Client 1\n    client1_first_session = therapy_notes[\"client1_session1\"]\n    client1_last_session = therapy_notes[\"client1_session2\"]\n    \n    # Extract NLP features from brief summary and chief complaint\n    client1_first_nlp = extract_nlp_features(\n        client1_first_session.get(\"Brief Summary of Session\", \"\") + \n        client1_first_session.get(\"Presentation\", {}).get(\"Chief Complaint\", \"\")\n    )\n    client1_last_nlp = extract_nlp_features(\n        client1_last_session.get(\"Brief Summary of Session\", \"\") + \n        client1_last_session.get(\"Presentation\", {}).get(\"Chief Complaint\", \"\")\n    )\n    \n    # Calculate symptom change vectors\n    client1_changes = calculate_symptom_change_vectors(client1_first_session, client1_last_session)\n    \n    # Add NLP features to changes\n    for key, value in client1_first_nlp.items():\n        client1_changes[f\"first_{key}\"] = value\n    for key, value in client1_last_nlp.items():\n        client1_changes[f\"last_{key}\"] = value\n        if f\"first_{key}\" in client1_changes:\n            client1_changes[f\"{key}_change\"] = value - client1_changes[f\"first_{key}\"]\n    \n    # Calculate comprehensive progress score\n    client1_progress_score = calculate_comprehensive_progress_score(client1_changes)\n    \n    # Generate progress report\n    client1_report = generate_progress_report(\n        \"client1\", \n        [\"client1_session1\", \"client1_session2\"], \n        client1_changes, \n        client1_progress_score\n    )\n    client_reports[\"client1\"] = client1_report\n    \n    # Process Client 2\n    client2_first_session = therapy_notes[\"client2_session1\"]\n    client2_last_session = therapy_notes[\"client2_session2\"]\n    \n    # Extract NLP features from brief summary and chief complaint\n    client2_first_nlp = extract_nlp_features(\n        client2_first_session.get(\"Brief Summary of Session\", \"\") + \n        client2_first_session.get(\"Presentation\", {}).get(\"Chief Complaint\", \"\")\n    )\n    client2_last_nlp = extract_nlp_features(\n        client2_last_session.get(\"Brief Summary of Session\", \"\") + \n        client2_last_session.get(\"Presentation\", {}).get(\"Chief Complaint\", \"\")\n    )\n    \n    # Calculate symptom change vectors\n    client2_changes = calculate_symptom_change_vectors(client2_first_session, client2_last_session)\n    \n    # Add NLP features to changes\n    for key, value in client2_first_nlp.items():\n        client2_changes[f\"first_{key}\"] = value\n    for key, value in client2_last_nlp.items():\n        client2_changes[f\"last_{key}\"] = value\n        if f\"first_{key}\" in client2_changes:\n            client2_changes[f\"{key}_change\"] = value - client2_changes[f\"first_{key}\"]\n    \n    # Calculate comprehensive progress score\n    client2_progress_score = calculate_comprehensive_progress_score(client2_changes)\n    \n    # Generate progress report\n    client2_report = generate_progress_report(\n        \"client2\", \n        [\"client2_session1\", \"client2_session2\"], \n        client2_changes, \n        client2_progress_score\n    )\n    client_reports[\"client2\"] = client2_report\n    \n    return client_reports\n\n# Execute the enhanced analysis\nclient_progress_reports = enhance_client_change_analysis()\n\n# Display results\nprint(\"=== Enhanced Therapy Progress Analysis ===\")\nfor client_id, report in client_progress_reports.items():\n    print(f\"\\nClient: {client_id}\")\n    print(f\"Progress Score: {report['progress_score']}\")\n    print(f\"Interpretation: {report['progress_interpretation']}\")\n    print(\"\\nStandardized Assessments:\")\n    print(f\"  First Session GAD-7: {report['standardized_assessments']['first_session']['gad7']} ({report['standardized_assessments']['first_session']['gad7_severity']})\")\n    print(f\"  Last Session GAD-7: {report['standardized_assessments']['last_session']['gad7']} ({report['standardized_assessments']['last_session']['gad7_severity']})\")\n    print(f\"  First Session PHQ-9: {report['standardized_assessments']['first_session']['phq9']} ({report['standardized_assessments']['first_session']['phq9_severity']})\")\n    print(f\"  Last Session PHQ-9: {report['standardized_assessments']['last_session']['phq9']} ({report['standardized_assessments']['last_session']['phq9_severity']})\")\n    print(\"\\nKey Contributing Factors:\")\n    for factor, score in report[\"score_factors\"].items():\n        print(f\"  {factor}: {score}\")\n\n# Create visualizations\nplt.figure(figsize=(12, 6))\n\nclient_ids = list(client_progress_reports.keys())\nprogress_scores = [report[\"progress_score\"] for report in client_progress_reports.values()]\n\n# Create bar chart of progress scores\nplt.subplot(1, 2, 1)\nplt.bar(client_ids, progress_scores, color=['green' if score > 0 else 'red' for score in progress_scores])\nplt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\nplt.title('Overall Therapy Progress Score')\nplt.ylabel('Progress Score (-10 to +10)')\nplt.grid(True, alpha=0.3)\n\n# Create radar chart for standardized assessments\nplt.subplot(1, 2, 2)\n\n# Data for radar chart - GAD7 and PHQ9 scores\ngad7_phq9_data = {\n    \"client1\": {\n        \"first_gad7\": client_progress_reports[\"client1\"][\"standardized_assessments\"][\"first_session\"][\"gad7\"],\n        \"last_gad7\": client_progress_reports[\"client1\"][\"standardized_assessments\"][\"last_session\"][\"gad7\"],\n        \"first_phq9\": client_progress_reports[\"client1\"][\"standardized_assessments\"][\"first_session\"][\"phq9\"],\n        \"last_phq9\": client_progress_reports[\"client1\"][\"standardized_assessments\"][\"last_session\"][\"phq9\"]\n    },\n    \"client2\": {\n        \"first_gad7\": client_progress_reports[\"client2\"][\"standardized_assessments\"][\"first_session\"][\"gad7\"],\n        \"last_gad7\": client_progress_reports[\"client2\"][\"standardized_assessments\"][\"last_session\"][\"gad7\"],\n        \"first_phq9\": client_progress_reports[\"client2\"][\"standardized_assessments\"][\"first_session\"][\"phq9\"],\n        \"last_phq9\": client_progress_reports[\"client2\"][\"standardized_assessments\"][\"last_session\"][\"phq9\"]\n    }\n}\n\n# Create simple bar chart of GAD7 and PHQ9 scores\nx = np.arange(2)\nwidth = 0.2\n\nplt.bar(x - width * 1.5, \n        [gad7_phq9_data[\"client1\"][\"first_gad7\"], gad7_phq9_data[\"client1\"][\"first_phq9\"]], \n        width, label='Client 1 First')\nplt.bar(x - width * 0.5, \n        [gad7_phq9_data[\"client1\"][\"last_gad7\"], gad7_phq9_data[\"client1\"][\"last_phq9\"]], \n        width, label='Client 1 Last')\nplt.bar(x + width * 0.5, \n        [gad7_phq9_data[\"client2\"][\"first_gad7\"], gad7_phq9_data[\"client2\"][\"first_phq9\"]], \n        width, label='Client 2 First')\nplt.bar(x + width * 1.5, \n        [gad7_phq9_data[\"client2\"][\"last_gad7\"], gad7_phq9_data[\"client2\"][\"last_phq9\"]], \n        width, label='Client 2 Last')\n\nplt.title('Standardized Assessment Scores')\nplt.xticks(x, ['GAD-7', 'PHQ-9'])\nplt.ylabel('Score (Higher = Worse)')\nplt.legend(loc='best')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print summary of approach and recommendations\nprint(\"\\n=== Therapy Progress Tracking Approach Summary ===\")\nprint(\"1. Standardized Assessment Integration:\")\nprint(\"   - GAD-7 for anxiety symptoms (0-21 scale)\")\nprint(\"   - PHQ-9 for depression symptoms (0-27 scale)\")\nprint(\"   - Automatic scoring based on session content analysis\")\n\nprint(\"\\n2. Feature Engineering Techniques:\")\nprint(\"   - Symptom intensity and frequency quantification\")\nprint(\"   - NLP sentiment and emotion analysis\")\nprint(\"   - Cognitive distortion pattern detection\")\nprint(\"   - Sleep and biological factor tracking\")\nprint(\"   - Risk assessment metrics\")\n\nprint(\"\\n3. Progress Scoring System:\")\nprint(\"   - Comprehensive weighted scoring (-10 to +10 scale)\")\nprint(\"   - Multiple contributing factors with domain-specific weighting\")\nprint(\"   - Standardized interpretation guidelines\")\n\nprint(\"\\n4. Recommendations for Production Implementation:\")\nprint(\"   - Implement structured data collection fields for GAD-7 and PHQ-9 questions\")\nprint(\"   - Add more demographic variables for context-aware progress interpretation\")\nprint(\"   - Develop longitudinal tracking for more than two sessions\")\nprint(\"   - Create therapist-facing dashboards for progress visualization\")\nprint(\"   - Incorporate treatment-specific expected progress benchmarks\")",
        "result": "\n=== Enhanced Therapy Progress Analysis ===\n\nClient: client1\nProgress Score: 18.28\nInterpretation: Excellent progress - significant symptom reduction and improved functioning\n\nStandardized Assessments:\n  First Session GAD-7: 7 (Mild anxiety)\n  Last Session GAD-7: 1 (Minimal anxiety)\n  First Session PHQ-9: 8 (Mild depression)\n  Last Session PHQ-9: 2 (Minimal depression)\n\nKey Contributing Factors:\n  gad7_total_score_change: 12.0\n  phq9_total_score_change: 12.0\n  avg_symptom_intensity_change: 1.5\n  mood_positive_change: 1.0\n  mood_negative_change: 1.0\n  has_sleep_issues_change: -0.0\n  has_hopelessness_change: -0.0\n  has_suicidal_thoughts_change: -0.0\n  sentiment_score_change: -1.0\n\nClient: client2\nProgress Score: -0.34\nInterpretation: Minimal change - symptom levels are relatively stable\n\nStandardized Assessments:\n  First Session GAD-7: 2 (Minimal anxiety)\n  Last Session GAD-7: 4 (Minimal anxiety)\n  First Session PHQ-9: 8 (Mild depression)\n  Last Session PHQ-9: 4 (Minimal depression)\n\nKey Contributing Factors:\n  gad7_total_score_change: -4.0\n  phq9_total_score_change: 8.0\n  avg_symptom_intensity_change: -1.5\n  mood_positive_change: 0.0\n  mood_negative_change: -0.0\n  has_sleep_issues_change: -1.0\n  has_hopelessness_change: -0.0\n  has_suicidal_thoughts_change: -0.0\n  sentiment_score_change: -2.0\n\n=== Therapy Progress Tracking Approach Summary ===\n1. Standardized Assessment Integration:\n   - GAD-7 for anxiety symptoms (0-21 scale)\n   - PHQ-9 for depression symptoms (0-27 scale)\n   - Automatic scoring based on session content analysis\n\n2. Feature Engineering Techniques:\n   - Symptom intensity and frequency quantification\n   - NLP sentiment and emotion analysis\n   - Cognitive distortion pattern detection\n   - Sleep and biological factor tracking\n   - Risk assessment metrics\n\n3. Progress Scoring System:\n   - Comprehensive weighted scoring (-10 to +10 scale)\n   - Multiple contributing factors with domain-specific weighting\n   - Standardized interpretation guidelines\n\n4. Recommendations for Production Implementation:\n   - Implement structured data collection fields for GAD-7 and PHQ-9 questions\n   - Add more demographic variables for context-aware progress interpretation\n   - Develop longitudinal tracking for more than two sessions\n   - Create therapist-facing dashboards for progress visualization\n   - Incorporate treatment-specific expected progress benchmarks,",
        "is_success": true,
        "is_finished": true,
        "assignee": "David",
        "start_at": 1748859143.3318446,
        "end_at": 1748859302.9949589
      },
      "3": {
        "task_id": "3",
        "dependent_task_ids": [
          "2"
        ],
        "instruction": "Create a framework for quantifying therapy progress using symptom analysis",
        "task_type": "model train",
        "code": "\n# Importing necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nimport xgboost as xgb\nimport pickle\nimport pandas as pd\nfrom matplotlib.colors import LinearSegmentedColormap\nimport matplotlib.patches as mpatches\nfrom matplotlib.gridspec import GridSpec\n\n# ----------------- 1. Data Preparation for Model Training -----------------\n\ndef prepare_model_training_data(client_progress_reports):\n    \"\"\"\n    Prepare training data for the progress prediction model\n    by creating synthetic data based on existing client reports\n    \"\"\"\n    # Create a dataframe from our existing client data\n    client_data = []\n    \n    # Extract features from our client progress reports\n    for client_id, report in client_progress_reports.items():\n        client_feature_dict = {}\n        \n        # Add base identifiers\n        client_feature_dict['client_id'] = client_id\n        client_feature_dict['progress_score'] = report['progress_score']\n        \n        # Add GAD-7 and PHQ-9 assessment scores\n        client_feature_dict['first_gad7'] = report['standardized_assessments']['first_session']['gad7']\n        client_feature_dict['last_gad7'] = report['standardized_assessments']['last_session']['gad7']\n        client_feature_dict['first_phq9'] = report['standardized_assessments']['first_session']['phq9']\n        client_feature_dict['last_phq9'] = report['standardized_assessments']['last_session']['phq9']\n        \n        # Extract change vectors\n        change_vectors = report['symptom_changes']\n        for key, value in change_vectors.items():\n            if isinstance(value, (int, float)) and '_change' in key:\n                client_feature_dict[key] = value\n        \n        client_data.append(client_feature_dict)\n    \n    # Convert to DataFrame\n    df = pd.DataFrame(client_data)\n    \n    # Since we only have 2 clients, we'll generate synthetic data for model training\n    # This is just for demonstration purposes - in production, you'd use real data\n    synthetic_samples = 100\n    synthetic_data = []\n    \n    for _ in range(synthetic_samples):\n        # Create a synthetic sample by randomly sampling from our features\n        # and applying small random variations\n        sample = {}\n        \n        # Randomly select one of our clients as a base\n        base_client = client_data[np.random.randint(0, len(client_data))]\n        \n        # Add features with slight variations\n        for key, value in base_client.items():\n            if key == 'client_id':\n                sample[key] = f\"synthetic_client_{_}\"\n            elif isinstance(value, (int, float)):\n                # Add random variation\n                if key == 'progress_score':\n                    # Ensure progress score remains in a reasonable range\n                    sample[key] = np.clip(value + np.random.normal(0, 2), -10, 10)\n                else:\n                    # For other numeric features, add smaller variations\n                    variation = np.random.normal(0, abs(value) * 0.2) if value != 0 else np.random.normal(0, 0.5)\n                    sample[key] = value + variation\n            else:\n                sample[key] = value\n        \n        # Make some coherent adjustments to maintain relationships between variables\n        # If GAD-7 decreases, progress should generally improve\n        gad7_change = sample['last_gad7'] - sample['first_gad7']\n        phq9_change = sample['last_phq9'] - sample['first_phq9']\n        \n        # Adjust progress score based on GAD-7 and PHQ-9 changes (negative change is good)\n        progress_adjustment = -(gad7_change + phq9_change) * 0.7\n        sample['progress_score'] = np.clip(sample['progress_score'] + progress_adjustment, -10, 10)\n        \n        synthetic_data.append(sample)\n    \n    # Combine real and synthetic data\n    all_data = client_data + synthetic_data\n    full_df = pd.DataFrame(all_data)\n    \n    return full_df\n\n# ----------------- 2. Therapy Progress Prediction Model -----------------\n\ndef build_progress_prediction_model(data_df):\n    \"\"\"\n    Build and train a model to predict therapy progress scores\n    \"\"\"\n    # Prepare feature matrix and target\n    # Remove client_id and target variable\n    X = data_df.drop(['client_id', 'progress_score'], axis=1, errors='ignore')\n    y = data_df['progress_score']\n    \n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Define models to try\n    models = {\n        'RandomForest': RandomForestRegressor(random_state=42),\n        'GradientBoosting': GradientBoostingRegressor(random_state=42),\n        'XGBoost': xgb.XGBRegressor(random_state=42)\n    }\n    \n    # Train and evaluate models\n    model_results = {}\n    \n    for name, model in models.items():\n        print(f\"Training {name}...\")\n        \n        if name == 'RandomForest':\n            param_grid = {\n                'n_estimators': [50, 100],\n                'max_depth': [None, 10, 20],\n                'min_samples_split': [2, 5],\n                'min_samples_leaf': [1, 2]\n            }\n        elif name == 'GradientBoosting':\n            param_grid = {\n                'n_estimators': [50, 100],\n                'learning_rate': [0.01, 0.1],\n                'max_depth': [3, 5],\n                'min_samples_split': [2, 5]\n            }\n        else:  # XGBoost\n            param_grid = {\n                'n_estimators': [50, 100],\n                'learning_rate': [0.01, 0.1],\n                'max_depth': [3, 5],\n                'subsample': [0.8, 1.0]\n            }\n        \n        grid_search = GridSearchCV(\n            model, param_grid, cv=5, scoring='neg_mean_squared_error'\n        )\n        grid_search.fit(X_train_scaled, y_train)\n        \n        # Get best model\n        best_model = grid_search.best_estimator_\n        \n        # Make predictions\n        y_pred = best_model.predict(X_test_scaled)\n        \n        # Evaluate\n        mse = mean_squared_error(y_test, y_pred)\n        mae = mean_absolute_error(y_test, y_pred)\n        r2 = r2_score(y_test, y_pred)\n        \n        model_results[name] = {\n            'model': best_model,\n            'mse': mse,\n            'mae': mae,\n            'r2': r2,\n            'best_params': grid_search.best_params_\n        }\n        \n        print(f\"{name} Results:\")\n        print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n        print(f\"Best Parameters: {grid_search.best_params_}\")\n        print(\"-\" * 50)\n    \n    # Select best model based on R²\n    best_model_name = max(model_results, key=lambda k: model_results[k]['r2'])\n    best_model_info = model_results[best_model_name]\n    \n    print(f\"\\nSelected Model: {best_model_name}\")\n    print(f\"MSE: {best_model_info['mse']:.4f}, MAE: {best_model_info['mae']:.4f}, R²: {best_model_info['r2']:.4f}\")\n    \n    # Feature importance\n    feature_importance = None\n    if best_model_name == 'RandomForest':\n        feature_importance = best_model_info['model'].feature_importances_\n    elif best_model_name == 'GradientBoosting':\n        feature_importance = best_model_info['model'].feature_importances_\n    elif best_model_name == 'XGBoost':\n        feature_importance = best_model_info['model'].feature_importances_\n    \n    if feature_importance is not None:\n        features = X.columns\n        importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n        importance_df = importance_df.sort_values('Importance', ascending=False)\n        print(\"\\nTop 10 Most Important Features:\")\n        print(importance_df.head(10))\n    \n    return {\n        'best_model': best_model_info['model'],\n        'best_model_name': best_model_name,\n        'scaler': scaler,\n        'feature_names': list(X.columns),\n        'feature_importance': importance_df if feature_importance is not None else None,\n        'metrics': {\n            'mse': best_model_info['mse'],\n            'mae': best_model_info['mae'],\n            'r2': best_model_info['r2']\n        }\n    }\n\n# ----------------- 3. Enhanced Visualization Framework -----------------\n\ndef create_enhanced_visualizations(client_progress_reports, model_info=None):\n    \"\"\"\n    Create enhanced visualizations for therapy progress\n    \"\"\"\n    plt.figure(figsize=(15, 20))\n    gs = GridSpec(4, 2, figure=plt.gcf())\n    \n    # Visualization 1: Overall Progress Score\n    ax1 = plt.subplot(gs[0, :])\n    client_ids = list(client_progress_reports.keys())\n    progress_scores = [report[\"progress_score\"] for report in client_progress_reports.values()]\n    \n    # Create custom colormap for the progress scores\n    colors = ['#d73027', '#f46d43', '#fdae61', '#fee08b', '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850']\n    cmap = LinearSegmentedColormap.from_list('progress_colors', colors)\n    norm = plt.Normalize(-10, 10)\n    \n    bar_colors = [cmap(norm(score)) for score in progress_scores]\n    \n    bars = ax1.bar(client_ids, progress_scores, color=bar_colors)\n    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n    ax1.set_title('Overall Therapy Progress Score', fontsize=16)\n    ax1.set_ylabel('Progress Score (-10 to +10)', fontsize=14)\n    ax1.grid(True, alpha=0.3)\n    \n    # Add text labels on top of bars\n    for bar, score in zip(bars, progress_scores):\n        height = bar.get_height()\n        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n                 f'{score:.1f}',\n                 ha='center', va='bottom', fontsize=12)\n    \n    # Add interpretation text below each bar\n    for i, client_id in enumerate(client_ids):\n        interpretation = client_progress_reports[client_id][\"progress_interpretation\"]\n        ax1.text(i, -10.5, interpretation, ha='center', va='top', \n                 fontsize=11, wrap=True, bbox=dict(facecolor='white', alpha=0.7))\n    \n    # Visualization 2: GAD-7 and PHQ-9 Score Changes\n    ax2 = plt.subplot(gs[1, 0])\n    \n    # Prepare data for GAD-7 and PHQ-9 visualization\n    assessment_data = []\n    for client_id, report in client_progress_reports.items():\n        first_gad7 = report[\"standardized_assessments\"][\"first_session\"][\"gad7\"] \n        last_gad7 = report[\"standardized_assessments\"][\"last_session\"][\"gad7\"]\n        first_phq9 = report[\"standardized_assessments\"][\"first_session\"][\"phq9\"]\n        last_phq9 = report[\"standardized_assessments\"][\"last_session\"][\"phq9\"]\n        \n        assessment_data.append({\n            'client_id': client_id,\n            'first_gad7': first_gad7,\n            'last_gad7': last_gad7,\n            'first_phq9': first_phq9,\n            'last_phq9': last_phq9,\n            'gad7_change': last_gad7 - first_gad7,\n            'phq9_change': last_phq9 - first_phq9\n        })\n    \n    assessment_df = pd.DataFrame(assessment_data)\n    \n    # Prepare for grouped bar chart\n    clients = assessment_df['client_id']\n    x = np.arange(len(clients))\n    width = 0.35\n    \n    # GAD-7 bars\n    gad7_bars = ax2.bar(x - width/2, assessment_df['first_gad7'], width, label='Initial GAD-7',\n                         color='#66c2a5', edgecolor='black', linewidth=1)\n    ax2.bar(x - width/2, assessment_df['gad7_change'], width,\n            bottom=assessment_df['first_gad7'], color='#fc8d62' if any(assessment_df['gad7_change'] > 0) else '#8da0cb',\n            edgecolor='black', linewidth=1)\n    \n    # PHQ-9 bars\n    phq9_bars = ax2.bar(x + width/2, assessment_df['first_phq9'], width, label='Initial PHQ-9',\n                         color='#ffd92f', edgecolor='black', linewidth=1)\n    ax2.bar(x + width/2, assessment_df['phq9_change'], width,\n            bottom=assessment_df['first_phq9'], color='#fc8d62' if any(assessment_df['phq9_change'] > 0) else '#8da0cb',\n            edgecolor='black', linewidth=1)\n    \n    # Add labels and legend\n    ax2.set_ylabel('Score', fontsize=14)\n    ax2.set_title('Standardized Assessment Changes', fontsize=16)\n    ax2.set_xticks(x)\n    ax2.set_xticklabels(clients)\n    \n    # Create custom legend\n    legend_elements = [\n        mpatches.Patch(facecolor='#66c2a5', edgecolor='black', label='Initial GAD-7'),\n        mpatches.Patch(facecolor='#ffd92f', edgecolor='black', label='Initial PHQ-9'),\n        mpatches.Patch(facecolor='#8da0cb', edgecolor='black', label='Score Decrease (Improvement)'),\n        mpatches.Patch(facecolor='#fc8d62', edgecolor='black', label='Score Increase (Deterioration)')\n    ]\n    ax2.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n    \n    # Add text annotations for the scores\n    for i, client in enumerate(clients):\n        # GAD-7 annotations\n        first_gad7 = assessment_df['first_gad7'].iloc[i]\n        last_gad7 = assessment_df['last_gad7'].iloc[i]\n        ax2.text(i - width/2, first_gad7 / 2, f\"{first_gad7:.0f}\", \n                 ha='center', va='center', color='black', fontsize=10)\n        ax2.text(i - width/2, first_gad7 + assessment_df['gad7_change'].iloc[i] / 2, \n                 f\"{assessment_df['gad7_change'].iloc[i]:+.0f}\", \n                 ha='center', va='center', color='black', fontsize=10)\n        \n        # PHQ-9 annotations\n        first_phq9 = assessment_df['first_phq9'].iloc[i]\n        last_phq9 = assessment_df['last_phq9'].iloc[i]\n        ax2.text(i + width/2, first_phq9 / 2, f\"{first_phq9:.0f}\", \n                 ha='center', va='center', color='black', fontsize=10)\n        ax2.text(i + width/2, first_phq9 + assessment_df['phq9_change'].iloc[i] / 2, \n                 f\"{assessment_df['phq9_change'].iloc[i]:+.0f}\", \n                 ha='center', va='center', color='black', fontsize=10)\n    \n    # Visualization 3: Radar Chart for Symptom Categories\n    ax3 = plt.subplot(gs[1, 1], polar=True)\n    \n    # Define symptom categories\n    categories = ['Anxiety', 'Depression', 'Sleep Issues', 'Interpersonal', 'Cognitive', 'Risk Factors']\n    \n    # Prepare data for radar chart\n    radar_data = []\n    for client_id, report in client_progress_reports.items():\n        # Extract category-related metrics from report\n        changes = report['symptom_changes']\n        \n        # Map metrics to categories\n        category_scores = {\n            'Anxiety': 0,\n            'Depression': 0,\n            'Sleep Issues': 0,\n            'Interpersonal': 0,\n            'Cognitive': 0,\n            'Risk Factors': 0\n        }\n        \n        # Anxiety indicators\n        if 'gad7_total_score_change' in changes:\n            category_scores['Anxiety'] = -changes['gad7_total_score_change'] # Negate so improvement is positive\n        \n        # Depression indicators\n        if 'phq9_total_score_change' in changes:\n            category_scores['Depression'] = -changes['phq9_total_score_change'] # Negate so improvement is positive\n        \n        # Sleep issues\n        if 'has_sleep_issues_change' in changes:\n            category_scores['Sleep Issues'] = -changes['has_sleep_issues_change'] * 5 # Negate so improvement is positive\n        \n        # Interpersonal factors\n        interpersonal_keys = [k for k in changes.keys() if 'relationship' in k.lower() or 'social' in k.lower()]\n        if interpersonal_keys:\n            avg_score = np.mean([-changes[k] for k in interpersonal_keys]) # Negate so improvement is positive\n            category_scores['Interpersonal'] = avg_score\n        \n        # Cognitive factors\n        if 'cognitive_distortion_count_change' in changes:\n            category_scores['Cognitive'] = -changes['cognitive_distortion_count_change'] * 2 # Negate so improvement is positive\n        \n        # Risk factors\n        risk_keys = ['has_hopelessness_change', 'has_suicidal_thoughts_change']\n        risk_values = [changes.get(k, 0) for k in risk_keys if k in changes]\n        if risk_values:\n            avg_risk = np.mean([-v * 5 for v in risk_values]) # Negate so improvement is positive\n            category_scores['Risk Factors'] = avg_risk\n        \n        # Scale all values to be between -10 and 10\n        for key in category_scores:\n            category_scores[key] = np.clip(category_scores[key], -10, 10)\n        \n        # Create a row for this client\n        values = [category_scores[cat] for cat in categories]\n        radar_data.append({\n            'client_id': client_id,\n            'values': values\n        })\n    \n    # Plot the radar chart\n    angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n    angles += angles[:1] # Close the loop\n    \n    # Add radial grid lines and labels\n    ax3.set_rlabel_position(0)\n    ax3.set_yticks([-10, -5, 0, 5, 10])\n    ax3.set_yticklabels(['-10', '-5', '0', '5', '10'])\n    ax3.grid(True)\n    \n    # Plot each client's data\n    for i, data in enumerate(radar_data):\n        values = data['values'] + data['values'][:1] # Close the loop\n        ax3.plot(angles, values, linewidth=2, linestyle='solid', label=data['client_id'])\n        ax3.fill(angles, values, alpha=0.25)\n    \n    # Set category labels\n    ax3.set_xticks(angles[:-1])\n    ax3.set_xticklabels(categories)\n    \n    # Add legend\n    ax3.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n    ax3.set_title('Symptom Category Changes', fontsize=16)\n    \n    # Visualization 4: Feature Importance from Model\n    ax4 = plt.subplot(gs[2, :])\n    \n    if model_info and model_info.get('feature_importance') is not None:\n        # Plot feature importance\n        importance_df = model_info['feature_importance']\n        top_features = importance_df.head(10)\n        \n        # Sort by importance\n        top_features = top_features.sort_values('Importance')\n        \n        # Plot horizontal bar chart\n        bars = ax4.barh(top_features['Feature'], top_features['Importance'], color='#3182bd')\n        ax4.set_title('Top 10 Features for Progress Prediction', fontsize=16)\n        ax4.set_xlabel('Importance', fontsize=14)\n        \n        # Add value labels\n        for i, bar in enumerate(bars):\n            width = bar.get_width()\n            ax4.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n                     f'{width:.4f}', ha='left', va='center', fontsize=10)\n    else:\n        ax4.text(0.5, 0.5, 'Model information not available', \n                 ha='center', va='center', fontsize=14)\n        ax4.axis('off')\n    \n    # Visualization 5: Individual Client Progress Timeline\n    ax5 = plt.subplot(gs[3, :])\n    \n    # Create a timeline visualization for each client\n    client_colors = ['#1b9e77', '#d95f02', '#7570b3', '#e7298a']\n    \n    # Create x-axis with session numbers\n    sessions = [1, 2]  # We currently have 2 sessions per client\n    \n    # For each client, plot GAD-7 and PHQ-9 scores across sessions\n    for i, client_id in enumerate(client_ids):\n        report = client_progress_reports[client_id]\n        gad7_scores = [\n            report[\"standardized_assessments\"][\"first_session\"][\"gad7\"],\n            report[\"standardized_assessments\"][\"last_session\"][\"gad7\"]\n        ]\n        \n        phq9_scores = [\n            report[\"standardized_assessments\"][\"first_session\"][\"phq9\"],\n            report[\"standardized_assessments\"][\"last_session\"][\"phq9\"]\n        ]\n        \n        # Plot GAD-7 scores\n        ax5.plot(sessions, gad7_scores, marker='o', linestyle='-', \n                 color=client_colors[i % len(client_colors)],\n                 label=f'{client_id} GAD-7')\n        \n        # Plot PHQ-9 scores with dashed line\n        ax5.plot(sessions, phq9_scores, marker='s', linestyle='--',\n                 color=client_colors[i % len(client_colors)], \n                 alpha=0.7, label=f'{client_id} PHQ-9')\n        \n        # Add annotations\n        for j, (gad7, phq9) in enumerate(zip(gad7_scores, phq9_scores)):\n            ax5.annotate(f'G:{gad7}', (sessions[j], gad7), \n                        textcoords=\"offset points\", xytext=(0,10), \n                        ha='center', fontsize=9,\n                        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.7))\n            \n            ax5.annotate(f'P:{phq9}', (sessions[j], phq9), \n                        textcoords=\"offset points\", xytext=(0,-15), \n                        ha='center', fontsize=9,\n                        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.7))\n    \n    # Set labels and title\n    ax5.set_title('Client Progress Timeline', fontsize=16)\n    ax5.set_xlabel('Session', fontsize=14)\n    ax5.set_ylabel('Assessment Score', fontsize=14)\n    ax5.set_xticks(sessions)\n    ax5.grid(True, alpha=0.3)\n    \n    # Add legend\n    ax5.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=4)\n    \n    # Adjust layout and spacing\n    plt.tight_layout()\n    plt.subplots_adjust(hspace=0.4)\n    \n    # Save figure if needed\n    plt.savefig('therapy_progress_dashboard.png', dpi=300, bbox_inches='tight')\n    \n    return plt\n\n# ----------------- 4. Progress Prediction Function -----------------\n\ndef predict_client_progress(model_info, client_data):\n    \"\"\"\n    Predict therapy progress for a client using the trained model\n    \n    Args:\n        model_info: Dictionary with model, scaler, and feature names\n        client_data: Dictionary with client features\n        \n    Returns:\n        Dictionary with predicted progress score and interpretation\n    \"\"\"\n    # Prepare input features\n    feature_names = model_info['feature_names']\n    \n    # Ensure client data has all required features\n    input_features = []\n    for feature in feature_names:\n        if feature in client_data:\n            input_features.append(client_data[feature])\n        else:\n            # If feature is missing, use 0 as default\n            input_features.append(0)\n    \n    # Convert to numpy array and reshape\n    input_array = np.array(input_features).reshape(1, -1)\n    \n    # Scale features\n    scaled_input = model_info['scaler'].transform(input_array)\n    \n    # Make prediction\n    predicted_score = model_info['best_model'].predict(scaled_input)[0]\n    \n    # Interpret score\n    interpretation = interpret_progress_score(predicted_score)\n    \n    return {\n        'predicted_progress_score': predicted_score,\n        'interpretation': interpretation,\n        'model_used': model_info['best_model_name']\n    }\n\n# ----------------- 5. Complete Therapy Progress Framework -----------------\n\ndef create_therapy_progress_framework():\n    \"\"\"\n    Create and demonstrate the complete therapy progress framework\n    \"\"\"\n    print(\"===== THERAPY PROGRESS TRACKING FRAMEWORK =====\")\n    \n    # 1. Prepare model training data\n    print(\"\\n1. Preparing model training data...\")\n    training_data = prepare_model_training_data(client_progress_reports)\n    print(f\"Generated dataset with {len(training_data)} samples\")\n    \n    # 2. Build and train the progress prediction model\n    print(\"\\n2. Building progress prediction model...\")\n    model_info = build_progress_prediction_model(training_data)\n    \n    # 3. Create enhanced visualizations\n    print(\"\\n3. Creating enhanced visualizations...\")\n    _ = create_enhanced_visualizations(client_progress_reports, model_info)\n    print(\"Enhanced visualizations created and saved as 'therapy_progress_dashboard.png'\")\n    \n    # 4. Demonstrate progress prediction for a new client\n    print(\"\\n4. Demonstrating progress prediction for a new client...\")\n    \n    # Create sample data for a new client\n    new_client_data = {\n        'first_gad7': 12,  # Starting with moderate anxiety\n        'last_gad7': 8,    # Some improvement in anxiety\n        'first_phq9': 14,  # Starting with moderate depression\n        'last_phq9': 10,   # Some improvement in depression\n        'gad7_total_score_change': -4,\n        'phq9_total_score_change': -4,\n        'avg_symptom_intensity_change': -1.0,\n        'mood_positive_change': 1,\n        'mood_negative_change': -1,\n        'has_sleep_issues_change': -1\n    }\n    \n    prediction_result = predict_client_progress(model_info, new_client_data)\n    \n    print(f\"Predicted Progress Score: {prediction_result['predicted_progress_score']:.2f}\")\n    print(f\"Interpretation: {prediction_result['interpretation']}\")\n    print(f\"Model Used: {prediction_result['model_used']}\")\n    \n    # 5. Save model for future use\n    print(\"\\n5. Saving model for future use...\")\n    model_output = {\n        'model': model_info['best_model'],\n        'scaler': model_info['scaler'],\n        'feature_names': model_info['feature_names'],\n        'model_name': model_info['best_model_name']\n    }\n    \n    with open('therapy_progress_model.pkl', 'wb') as f:\n        pickle.dump(model_output, f)\n    \n    print(\"Model saved as 'therapy_progress_model.pkl'\")\n    \n    print(\"\\n===== FRAMEWORK CREATION COMPLETE =====\")\n    return {\n        'model_info': model_info,\n        'visualizations': 'therapy_progress_dashboard.png',\n        'model_file': 'therapy_progress_model.pkl',\n        'training_data_size': len(training_data)\n    }\n\n# Execute the framework creation\nframework_info = create_therapy_progress_framework()\n\n# Provide a summary of the framework components\nprint(\"\\n===== FRAMEWORK SUMMARY =====\")\nprint(f\"1. Model Performance: R² = {framework_info['model_info']['metrics']['r2']:.4f}\")\nprint(f\"2. Training Data Size: {framework_info['training_data_size']} samples\")\nprint(f\"3. Model Type: {framework_info['model_info']['best_model_name']}\")\nprint(f\"4. Visualizations: {framework_info['visualizations']}\")\nprint(f\"5. Saved Model: {framework_info['model_file']}\")",
        "result": "\n===== THERAPY PROGRESS TRACKING FRAMEWORK =====\n\n1. Preparing model training data...\nGenerated dataset with 102 samples\n\n2. Building progress prediction model...\nTraining RandomForest...\nRandomForest Results:\nMSE: 6.8899, MAE: 1.6144, R²: 0.7491\nBest Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n--------------------------------------------------\nTraining GradientBoosting...\nGradientBoosting Results:\nMSE: 7.6736, MAE: 1.7277, R²: 0.7205\nBest Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100}\n--------------------------------------------------\nTraining XGBoost...\nXGBoost Results:\nMSE: 6.2548, MAE: 1.5489, R²: 0.7722\nBest Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n--------------------------------------------------\n\nSelected Model: XGBoost\nMSE: 6.2548, MAE: 1.5489, R²: 0.7722\n\nTop 10 Most Important Features:\n                          Feature  Importance\n15           phq9_thoughts_change    0.582302\n0                      first_gad7    0.088906\n11        gad7_total_score_change    0.077094\n6              phq9_moving_change    0.051722\n25       has_substance_use_change    0.037216\n8       frequency_frequent_change    0.020887\n23            gad7_feeling_change    0.017552\n28           mood_positive_change    0.015688\n4   frequency_intermittent_change    0.013721\n2                      first_phq9    0.010553\n\n3. Creating enhanced visualizations...\nEnhanced visualizations created and saved as 'therapy_progress_dashboard.png'\n\n4. Demonstrating progress prediction for a new client...\nPredicted Progress Score: 3.61\nInterpretation: Moderate progress - some symptom reduction with minimal functional improvement\nModel Used: XGBoost\n\n5. Saving model for future use...\nModel saved as 'therapy_progress_model.pkl'\n\n===== FRAMEWORK CREATION COMPLETE =====\n\n===== FRAMEWORK SUMMARY =====\n1. Model Performance: R² = 0.7722\n2. Training Data Size: 102 samples\n3. Model Type: XGBoost\n4. Visualizations: therapy_progress_dashboard.png\n5. Saved Model: therapy_progress_model.pkl,",
        "is_success": true,
        "is_finished": true,
        "assignee": "David",
        "start_at": 1748859303.0116413,
        "end_at": 1748859546.3915954
      }
    }
  },
  "gallery_last_file": {},
  "timeline_status": {
    "1": 1,
    "2": 1,
    "3": 1,
    "4": 1,
    "5": 1,
    "6": 1,
    "7": 1,
    "8": 1,
    "9": 1,
    "10": 1,
    "11": 1,
    "12": 1,
    "13": 1,
    "14": 1,
    "15": 1,
    "16": 1,
    "17": 1,
    "18": 1,
    "19": 1,
    "20": 1,
    "21": 1,
    "22": 1,
    "23": 1,
    "24": 1,
    "25": 1,
    "26": 1,
    "27": 1,
    "28": 1,
    "29": 1,
    "30": 1,
    "31": 1,
    "32": 1,
    "33": 1,
    "34": 1,
    "35": 1,
    "36": 1,
    "37": 1,
    "38": 1,
    "39": 1,
    "40": 1,
    "41": 1,
    "42": 1,
    "43": 1,
    "44": 1,
    "45": 1,
    "46": 1,
    "47": 1,
    "48": 1,
    "50": 0,
    "51": 0,
    "53": 0,
    "54": 0,
    "55": 1,
    "56": 1,
    "57": 1,
    "58": 1,
    "59": 1,
    "60": 1,
    "61": 1,
    "62": 1,
    "63": 1
  },
  "preview_servers": {},
  "deploy": {}
}